{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Tam Model Kar≈üƒ±la≈ütƒ±rmasƒ±\n",
                "\n",
                "Bu notebook t√ºm **√úCRETSƒ∞Z** modelleri kar≈üƒ±la≈ütƒ±rƒ±r.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys, os, gc\n",
                "import torch\n",
                "import pandas as pd\n",
                "from PIL import Image\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "PROJECT_ROOT = os.path.dirname(os.getcwd())\n",
                "sys.path.insert(0, PROJECT_ROOT)\n",
                "\n",
                "from src.utils import PromptManager, print_model_table, FREE_MODELS, COLAB_MODELS\n",
                "from src.evaluation.nlp_metrics import BLEUEvaluator, ROUGEEvaluator\n",
                "\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "print_model_table()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üÜì Sadece √úcretsiz Modeller"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n‚úÖ Colab T4 i√ßin test edilecek modeller:\")\n",
                "for m in COLAB_MODELS:\n",
                "    print(f\"  üÜì {m}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model y√ºkleyiciler\n",
                "def load_qwen2_vl():\n",
                "    from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
                "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-2B-Instruct\")\n",
                "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
                "        \"Qwen/Qwen2-VL-2B-Instruct\", torch_dtype=torch.float16, device_map=\"auto\"\n",
                "    )\n",
                "    return model, processor\n",
                "\n",
                "def run_qwen2_vl(model, processor, image, prompt):\n",
                "    messages = [{\"role\": \"user\", \"content\": [\n",
                "        {\"type\": \"image\", \"image\": image},\n",
                "        {\"type\": \"text\", \"text\": prompt}\n",
                "    ]}]\n",
                "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
                "    inputs = processor(text=[text], images=[image], return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
                "    output_ids = model.generate(**inputs, max_new_tokens=512)\n",
                "    return processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
                "\n",
                "def clear_gpu():\n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache()\n",
                "    print(f\"GPU: {torch.cuda.memory_allocated()/1e9:.1f} GB\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test ayarlarƒ±\n",
                "test_image_path = os.path.join(PROJECT_ROOT, \"test_xray.png\")\n",
                "image = Image.open(test_image_path).convert(\"RGB\")\n",
                "\n",
                "pm = PromptManager()\n",
                "prompt = pm.get_prompt(\"rrg\", \"detailed\").user_prompt\n",
                "\n",
                "reference = \"FINDINGS: Normal heart size. Clear lungs. IMPRESSION: Normal chest X-ray.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Kar≈üƒ±la≈ütƒ±rma\n",
                "MODELS = [\n",
                "    (\"Qwen2-VL-2B\", load_qwen2_vl, run_qwen2_vl),\n",
                "]\n",
                "\n",
                "results = []\n",
                "\n",
                "for name, load_fn, run_fn in MODELS:\n",
                "    print(f\"\\nüîÑ {name}...\")\n",
                "    try:\n",
                "        model, processor = load_fn()\n",
                "        output = run_fn(model, processor, image, prompt)\n",
                "        results.append({\"model\": name, \"output\": output})\n",
                "        print(f\"‚úÖ {len(output)} karakter\")\n",
                "        del model, processor\n",
                "        clear_gpu()\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå {e}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Deƒüerlendirme\n",
                "bleu = BLEUEvaluator()\n",
                "rouge = ROUGEEvaluator()\n",
                "\n",
                "eval_results = []\n",
                "for r in results:\n",
                "    scores = bleu.compute([r[\"output\"]], [reference])\n",
                "    scores.update(rouge.compute([r[\"output\"]], [reference]))\n",
                "    eval_results.append({\"model\": r[\"model\"], **scores})\n",
                "\n",
                "pd.DataFrame(eval_results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sonu√ßlarƒ± kaydet\n",
                "import json\n",
                "with open(os.path.join(PROJECT_ROOT, \"results\", \"comparison_results.json\"), \"w\") as f:\n",
                "    json.dump({\"results\": results, \"evaluation\": eval_results}, f, indent=2)\n",
                "print(\"‚úÖ Kaydedildi!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}